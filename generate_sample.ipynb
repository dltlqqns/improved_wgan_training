{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.datasets\n",
    "\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "#import tflib.small_imagenet\n",
    "import tflib.web_oneclass\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot\n",
    "import os\n",
    "\n",
    "DIM = 32 # Model dimensionality\n",
    "DEVICES = 0\n",
    "NUM_SAMPLE = 100\n",
    "TARGET_SIZE = 128\n",
    "OUTPUT_DIM = TARGET_SIZE*TARGET_SIZE*3 # Number of pixels in each iamge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LeakyReLU(x, alpha=0.2):\n",
    "    return tf.maximum(alpha*x, x)\n",
    "\n",
    "def ReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(name+'.Linear', n_in, n_out, inputs, initialization='he')\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "def LeakyReLULayer(name, n_in, n_out, inputs):\n",
    "    output = lib.ops.linear.Linear(name+'.Linear', n_in, n_out, inputs, initialization='he')\n",
    "    return LeakyReLU(output)\n",
    "\n",
    "def Batchnorm(name, axes, inputs):\n",
    "    if ('Discriminator' in name) and (MODE == 'wgan-gp'):\n",
    "        if axes != [0,2,3]:\n",
    "            raise Exception('Layernorm over non-standard axes is unsupported')\n",
    "        return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)\n",
    "    else:\n",
    "        return lib.ops.batchnorm.Batchnorm(name,axes,inputs,fused=True)\n",
    "\n",
    "def DCGANGenerator_128(n_samples, noise=None, dim=DIM, bn=True, nonlinearity=tf.nn.relu):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128, 4*4*16*dim, noise)\n",
    "    output = tf.reshape(output, [-1, 16*dim, 4, 4])\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN1', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.2', 16*dim, 8*dim, 5, output)\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN2', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.3', 8*dim, 4*dim, 5, output)\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN3', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.4', 4*dim, 2*dim, 5, output)\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN4', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.5', 2*dim, dim, 5, output)\n",
    "    if bn:\n",
    "        output = Batchnorm('Generator.BN5', [0,2,3], output)\n",
    "    output = nonlinearity(output)\n",
    "\n",
    "    output = lib.ops.deconv2d.Deconv2D('Generator.6', dim, 3, 5, output)\n",
    "    output = tf.tanh(output)\n",
    "\n",
    "    lib.ops.conv2d.unset_weights_stdev()\n",
    "    lib.ops.deconv2d.unset_weights_stdev()\n",
    "    lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM])\n",
    "\n",
    "def nchw_to_nhwc(x):\n",
    "    return tf.transpose(x, [0,2,3,1])\n",
    "def nhwc_to_nchw(x):\n",
    "    return tf.transpose(x, [0,3,1,2])\n",
    "def BEGANGenerator(n_samples, noise=None, dim=DIM):\n",
    "    if noise is None:\n",
    "        noise = tf.random_normal([n_samples, 128])\n",
    "\n",
    "    output = lib.ops.linear.Linear('Generator.Input', 128, 8*8*dim, noise)\n",
    "    output = tf.reshape(output, [-1, dim, 8, 8])\n",
    "\n",
    "    repeat_num = int(np.log2(TARGET_SIZE/8)) + 1\n",
    "    curr_shape = 8\n",
    "    for idx in range(repeat_num):\n",
    "        output = lib.ops.conv2d.Conv2D('Generator.{}a'.format(idx+2), dim, dim, 3, output, stride=1)\n",
    "        output = LeakyReLU(output)\n",
    "        output = lib.ops.conv2d.Conv2D('Generator.{}b'.format(idx+2), dim, dim, 3, output, stride=1)\n",
    "        output = LeakyReLU(output)\n",
    "        if idx < repeat_num - 1:\n",
    "            output = nchw_to_nhwc(output)\n",
    "            output = tf.image.resize_nearest_neighbor(output, (curr_shape*2, curr_shape*2))\n",
    "            output = nhwc_to_nchw(output)\n",
    "            curr_shape = curr_shape * 2\n",
    "    print(curr_shape)\n",
    "\n",
    "    output = lib.ops.conv2d.Conv2D('Generator.{}'.format(repeat_num+2), dim, 3, 3, output)\n",
    "    output = tf.tanh(output)\n",
    "\n",
    "    return tf.reshape(output, [-1, OUTPUT_DIM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    Generator = BEGANGenerator\n",
    "    # For generating samples\n",
    "    fixed_noise = tf.constant(np.random.normal(size=(NUM_SAMPLE, 128)).astype('float32'))\n",
    "    all_fixed_noise_samples = Generator(NUM_SAMPLE, noise=fixed_noise)\n",
    "    if tf.__version__.startswith('1.'):\n",
    "        all_fixed_noise_samples = tf.concat(all_fixed_noise_samples, axis=0)\n",
    "    else:\n",
    "        all_fixed_noise_samples = tf.concat(0, all_fixed_noise_samples)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, 'models/BEGAN128_wgan-gp_horse_Mhidden32/model.ckpt-100000')\n",
    "    samples = session.run(all_fixed_noise_samples)\n",
    "    samples = ((samples+1.)*(255.99/2)).astype('int32')\n",
    "    lib.save_images.save_images(samples.reshape((NUM_SAMPLE, 3, TARGET_SIZE, TARGET_SIZE)), 'tmp.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
